#!/usr/bin/env python
import optparse
import sys
import random
import bleu
#from lr import LogisticRegression as lreg
import pickle, codecs
from sklearn import svm

optparser = optparse.OptionParser()
optparser.add_option("-d", "--dev", dest="dev", default="data/dev.100best", help="100-best dev translation lists")
optparser.add_option("-r", "--ref", dest="ref", default="data/dev.ref", help="dev reference")
optparser.add_option("-s", "--src", dest="src", default="data/dev.src", help="dev source")
optparser.add_option("-t", "--test-src", dest="tsrc", default="data/test.src", help="test source")
optparser.add_option("-k", "--kbest-list", dest="input", default="data/test.100best", help="100-best translation lists")
optparser.add_option("-z", "--sample", dest="sample", default=50, type="int", help="Sample size")
optparser.add_option("-m", "--meteorfile", dest="mfile", default='', help="Location of meteor file, if not given, BLEU will be used")
(opts, _) = optparser.parse_args()

fprobs, eprobs = pickle.load(open("lexprobs.pkl", "rb"))

all_ref = [line.strip() for line in open(opts.ref)]
all_src = [line.strip() for line in codecs.open(opts.src, "r", "utf-8")]
all_dev = [pair.split(' ||| ') for pair in codecs.open(opts.dev, 'r', 'utf-8')]
scores = []
if opts.mfile == '':
	print >>sys.stderr, "Using dev BLEU scores"
	import bleu
	for snum, ref in enumerate(all_ref):
		hyps = all_dev[snum*100:snum*100 + 100]
		for hyp in hyps:
			scores.append(bleu.bleu([x for x in bleu.bleu_stats(hyp, ref)]))
else:
	print >>sys.stderr, "Using dev METEOR scores"
	for line in open(opts.mfile):
		if "Segment " in line:
			parts = line.strip().split("\t")
			scores.append(float(parts[1])) 
print >>sys.stderr, "Sampling %d pairs for training from each hypotheses set"%opts.sample

logfh = codecs.open("/tmp/log", "w", "utf-8")

def count_foreign_words(s):
	fc = 0
	for w in s.split():
		try:
			w.encode('ascii')
		except:
			fc += 1
	return fc

def get_diff_feats(src, hyp1, hyp2):
	_, h1, feat1 = hyp1
	_, h2, feat2 = hyp2
	diff_feats = {}
	for f1, f2 in zip(feat1.split(' '), feat2.split(' ')):
		k1, v1 = f1.split('=')
		k2, v2 = f2.split('=')
		diff_feats[k1] = float(v1) - float(v2)
	# Additional features
	swords = src.split()
	t1words = h1.split()
	t2words = h2.split()
	t1s_numalign = 0
	st1_numalign = 0
	t2s_numalign = 0
	st2_numalign = 0
	for w in swords:
		if w not in fprobs:
			continue
		taligns = fprobs[w]
		for tw in t1words:
			if tw in taligns:
				st1_numalign+=1
		for tw in t2words:
			if tw in taligns:
				st2_numalign+=1
	for w in t1words:
		if w not in eprobs:
			continue
		saligns = eprobs[w]
		for sw in swords:
			if sw in saligns:
				t1s_numalign+=1
	for w in t2words:
		if w not in eprobs:
			continue
		saligns = eprobs[w]
		for sw in swords:
			if sw in saligns:
				t2s_numalign+=1
	
	diff_feats["num_stalign_diff"] = st1_numalign - st2_numalign
	diff_feats["num_tsalign_diff"] = t1s_numalign - t2s_numalign
	diff_feats["num_word_diff"] = len(t1words) - len(t2words)
	diff_feats["num_foreign_words"] = count_foreign_words(h1) - count_foreign_words(h2)
	return h1, h2, diff_feats

train_data = []
print >>sys.stderr, "src", len(all_src), "dev", len(all_dev), "ref", len(all_ref), "scores", len(scores)
for snum, (src, ref) in enumerate(zip(all_src, all_ref)):
	print >>sys.stderr, snum
	hyps_with_scores = zip(all_dev, scores)[snum *100:snum * 100 + 100]
	samples = []
	for _ in range(opts.sample):
		samples.append(tuple(random.sample(hyps_with_scores, 2)))
	for (hyp1, hyp1score), (hyp2, hyp2score) in samples:
		h1, h2, diff_feats = get_diff_feats(src, hyp1, hyp2)
		train_data.append([int(hyp1score > hyp2score), diff_feats])
			

#classifier = lreg()
#classifier.train(train_data, 10)	
classifier = svm.LinearSVC()
featnames = train_data[0][1].keys()
X = []
y = []
for datum in train_data:
	y.append(datum[0])
	x = []
	for fn in featnames:
		x.append(datum[1][fn])
	X.append(x)
classifier.fit(X, y)

#weights = {'p(e)': float(opts.lm),
#	   'p(e|f)' : float(opts.tm1),
#	   'p_lex(f|e)': float(opts.tm2)}

all_hyps = [pair.split(' ||| ') for pair in open(opts.input)]
all_test_src = [line.strip() for line in codecs.open(opts.tsrc, "r", "utf-8")]
num_sents = len(all_hyps) / 100
for s in xrange(0, num_sents):
	hyps = all_hyps[s * 100:s * 100 + 100]
	src = all_test_src[s]
	#(best_score, best) = (-1e300, '')
	#for (num, hyp, feats) in hyps_for_one_sent:
	#	score = 0.0
	#	for feat in feats.split(' '):
	#		(k, v) = feat.split('=')
	#		score += weights[k] * float(v)
	#	if score > best_score:
	#		(best_score, best) = (score, hyp)
	best_hyp = hyps[0]
	best = best_hyp[1]
	for hyp in hyps[1:]:
		h1, h2, diff_feats = get_diff_feats(src, hyp, best_hyp)
		#decision = classifier.classify(diff_feats)
		x = []
		for fn in featnames:
			x.append(diff_feats[fn])
		decision = classifier.predict(x)
		if decision == 1:
			best = h1
			best_hyp = hyp
			
	try: 
		sys.stdout.write("%s\n" % best)
	except (Exception):
		sys.exit(1)

