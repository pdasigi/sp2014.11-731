#!/usr/bin/env python

import argparse
import json
import os, sys, math
from util import compare_clusters
from nltk.tokenize import word_tokenize

def get_precision_recall(hwords, rwords):
  hypset = set(hwords)
  refset = set(rwords)
  precision = sum(1.0 for word in hwords if word in refset) / len(hwords)
  recall = sum(1.0 for word in rwords if word in hypset) / len(rwords)
  return precision, recall 

def get_ngrams(l, n):
  ng = []
  for i in range(len(l) - n + 1):
    ng.append(tuple([l[j] for j in range(i, i+n)]))
  return ng

def ngram_prec_rec(hwords, rwords, n):
  if len(hwords) < n or len(rwords) < n:
    return ngram_prec_rec(hwords, rwords, n-1)
  hng = get_ngrams(hwords, n)
  rng = get_ngrams(rwords, n)
  return get_precision_recall(hng, rng)

def get_bleu(hwords, rwords):
  c = len(hwords)
  r = len(rwords)
  if c > r:
    BP = 1.0
  else:
    BP = math.exp(1 - float(r)/c)
  N = min(c, r)
  logprecsum = 0.0
  #norm = 0
  for n in range(1, N+1):
    prec, _ = ngram_prec_rec(hwords, rwords, n)
    if prec != 0:
      #norm+=1
      logprecsum += math.log(prec)
  #return BP * math.exp(logprecsum)
  if logprecsum == 0:
    return 0.0
  return math.exp(logprecsum/N)

def extract_features(hyp, ref, hypc, refc, aligns):
  #hwords_tok = [x.lower() for x in word_tokenize(hyp)]
  #rwords_tok = [x.lower() for x in word_tokenize(ref)]
  hwords = hyp.split()
  rwords = ref.split()
  #print >>sys.stderr, hwords_tok, rwords_tok, hwords, rwords
  htrwords = [x[:4] for x in hwords]
  rtrwords = [x[:4] for x in rwords]
  hclust = [x[:3] for x in hypc.split()]
  rclust = [x[:3] for x in refc.split()]
  #hclust = hypc.split()
  #rclust = refc.split()
  prec, rec = get_precision_recall(hwords, rwords)
  trprec, trrec = get_precision_recall(htrwords, rtrwords)
  cprec, crec = get_precision_recall(hclust, rclust)
  bigramprec, bigramrec = ngram_prec_rec(hwords, rwords, 2)
  trigramprec, trigramrec = ngram_prec_rec(hwords, rwords, 3)
  tr_bigramprec, tr_bigramrec = ngram_prec_rec(htrwords, rtrwords, 2)
  cl_bigramprec, cl_bigramrec = ngram_prec_rec(hclust, rclust, 2)
  alratio = float(len(aligns))/len(hwords)
  #bleu = get_bleu(hwords, rwords)
  return {'prec':prec, 'rec':rec, "trrec":trrec, "trprec":trprec, "biprec":bigramprec, "birec":bigramrec}
  #return {'prec':prec, 'rec':rec, "trrec":trrec, "trprec":trprec, "biprec":bigramprec, "birec":bigramrec, "tr_bigramprec":tr_bigramprec, "tr_bigramrec":tr_bigramrec, "cl_bigramprec":cl_bigramprec, "cl_bigramrec":cl_bigramrec}
  #return {'prec':prec, 'rec':rec, "trrec":trrec, "trprec":trprec, "biprec":bigramprec, "birec":bigramrec, "trbiprec":trbigramprec, "trbirec":trbigramrec}
  #return {'prec':precision, 'rec':recall, "trrec":trrec, "trpres":trprec, "cluster_cosine": compare_clusters(hclust, rclust)}
  #return {'prec':precision, 'rec':recall, "trpres":trprec, "trrec":trrec, "cprec":cprec, "crec":crec, "word_cosine":compare_clusters(hwords, rwords)}
  #return {'prec':precision, 'rec':recall, "trrec":trrec, "trpres":trprec, "word_cosine": compare_clusters(htrwords, rtrwords), "cluster_cosine": compare_clusters(hclust, rclust), "aligned_ratio":alratio}
  #return {'prec':precision, 'rec':recall, "trpres":trprec, "trrec":trrec, "cprec":cprec, "crec":crec, "cosine": compare_clusters(hclust, rclust)}

argparser = argparse.ArgumentParser(prog='extract')
argparser.add_argument('-x', '--pairs', dest='pairs', default='data/en-cs.pairs', help='Reference-Hypothesis pairs')
argparser.add_argument('-a', '--aligns', dest='aligns', default='forwardalign-snb.txt', help='Reference-Hypothesis alignments')
argparser.add_argument('-c', '--clustered', dest='clustered', default='data/en-cs.pairs.all_clusters', help='Clustered Reference-Hypothesis pairs')

args = argparser.parse_args()

lc = 0
sys.stderr.write('Extracting features for (ref,hyp) pairs from %s.\n' % args.pairs)
# loop over all (ref,hyp) pairs in the input file and extract evaluation features
for ref_hyp, align, clust in zip(open(args.pairs), open(args.aligns), open(args.clustered)):
  lc += 1
  ref, hyp = ref_hyp.rstrip().split(' ||| ')
  refc, hypc = clust.rstrip().split(' ||| ')
  #algncnt = len(align.strip().split())
  fmap = extract_features(hyp, ref, hypc, refc, [(int(x.split('-')[0]), int(x.split('-')[1])) for x in align.strip().split()])
  print json.dumps({key: round(fmap[key], 5) for key in fmap})   # print evaluation feature map

